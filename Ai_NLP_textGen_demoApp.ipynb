{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xZee/Ai_NLP_textGen_DemoApp/blob/main/Ai_NLP_textGen_demoApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Demo App for Text Generation\n",
        "- NLP models : `gpt2-medium`, `openai-gpt`\n",
        "- Task : `text-generation`\n",
        "- speech-to-text : `gTTS`\n",
        "- DemoApp : `gradio`\n",
        "\n",
        "`0xZee`"
      ],
      "metadata": {
        "id": "vAsdIDnNTk3i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IDyj-7K6cZe"
      },
      "outputs": [],
      "source": [
        "# Dependencies : HuggingFace/Transformers, gTTS (text2speech) and Gradio for rendering\n",
        "# models NLP : gpt2-medium, openai-gpt\n",
        "! pip install gradio transformers gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "WthTbpEX6esN",
        "outputId": "ecb28fdc-b6fb-45c4-e2b7-785a6ce41c3d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://b66154324d37890944.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b66154324d37890944.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b66154324d37890944.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from gtts import gTTS\n",
        "\n",
        "# gpt2-large model text generation\n",
        "def text_gen(prompt):\n",
        "  generator = pipeline(\"text-generation\", model='gpt2-medium')\n",
        "  #generator = pipeline(\"text-generation\", model='distilgpt2')\n",
        "  #res_base = generator(prompt, max_new_tokens=100, num_return_sequences=1)\n",
        "  #res_p = generator(prompt, max_new_tokens=100, num_return_sequences=1, do_sample=True, top_p=0.095)\n",
        "  #res_k = generator(prompt, max_new_tokens=120, num_return_sequences=1, do_sample=True, top_k=4)\n",
        "  #res_c = generator(prompt, max_new_tokens=100, num_return_sequences=1, penalty_alpha=0.6, top_k=4)\n",
        "  #<span style=\"font-family:Papyrus; font-size:2em;\">👽 0xZee</span>\n",
        "  res = generator(prompt, max_new_tokens=100, num_return_sequences=1)\n",
        "  res = res[0]['generated_text']\n",
        "  # text_to_audio\n",
        "  audio = gTTS(text=res, lang='en', slow=False)\n",
        "  audio.save(\"res.wav\")\n",
        "  return(res , \"res.wav\")\n",
        "\n",
        "def complete_with_gpt(text):\n",
        "  complete = pipeline(\"text-generation\", model='openai-gpt')\n",
        "  res = complete(text[-50:], max_new_tokens=100, num_return_sequences=1)\n",
        "  return res[0]['generated_text']\n",
        "\n",
        "\n",
        "##\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "      gr.Markdown(\"\"\"\n",
        "                  > 👽 0xZee\n",
        "                  # 📝 NLP : GPT Text Generation & Text-to-Speech Demo\n",
        "                  > Demo #1 : **gtp2** Model (finetuned) and **gTTS** for text to audio\n",
        "                  *Enter a text with context : Will genrate text and display audio.*\n",
        "                  \"\"\")\n",
        "#\n",
        "    with gr.Row():\n",
        "        with gr.Column():   \n",
        "          prompt = gr.Textbox(label=\"Text Generation\", placeholder=\"Text and context here\")\n",
        "          gr.Examples(examples=[\"The Ai can help the world with\", \"The Moon's orbit around Earth has\" , \"John is a cowboy, suddenly he\"], inputs=[prompt])\n",
        "          btn = gr.Button(value=\"Go GPT\")\n",
        "#\n",
        "        with gr.Column():   \n",
        "          audio_out = gr.Audio()\n",
        "          text_out = gr.Textbox(label=\"tuned mode\")\n",
        "          btn.click(fn=text_gen, inputs=prompt, outputs=[text_out,audio_out])\n",
        "#\n",
        "    with gr.Row():\n",
        "      gr.Markdown(\"\"\"\n",
        "                  #\n",
        "                  # 🎲 NLP : GPT Text Auto Complete\n",
        "                  > Demo #2 : Auto-Complete : **openai-gpt** Model \n",
        "                  *Enter a text : will complete the text provided.*\n",
        "                  \"\"\")\n",
        "#\n",
        "    with gr.Row():\n",
        "          text = gr.Textbox(label=\"Text Complete\", placeholder=\"Text here\", lines=4)\n",
        "    with gr.Row():\n",
        "          gr.Examples(examples=[\"The Ai can help the world with\", \"tell me a story about\" , \"John is a cowboy, suddenly he is\"], inputs=[text])     \n",
        "    with gr.Row():          \n",
        "          btn = gr.Button(value=\"Go & Complete\")\n",
        "          btn.click(fn=complete_with_gpt, inputs=text, outputs=text, queue=False)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHLH0YXpCgnRPUbUXsMxm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}